{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.jpg\" width=\"100%\" />\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"5\"> <b>Prepare a SAR Data Stack</b><img style=\"padding: 7px\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\"/></font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Franz J Meyer and Alex Lewandowski; University of Alaska Fairbanks </b> <br>\n",
    "</font>\n",
    "\n",
    "<font size=\"3\"> This notebook downloads an ASF-Hyp3 subscription and prepares a deep multi-temporal SAR image data stack for use in other notebooks.</font></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"5\" color=\"red\"> <b>Important Note about JupyterHub</b> </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook.</b> </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 0. Importing Relevant Python Packages </b> </font>\n",
    "\n",
    "<font size=\"3\">In this notebook we will use the following scientific libraries:\n",
    "<ol type=\"1\">\n",
    "    <li> <b><a href=\"https://www.gdal.org/\" target=\"_blank\">GDAL</a></b> is a software library for reading and writing raster and vector geospatial data formats. It includes a collection of programs tailored for geospatial data processing. Most modern GIS systems (such as ArcGIS or QGIS) use GDAL in the background.</li>\n",
    "    <li> <b><a href=\"http://www.numpy.org/\" target=\"_blank\">NumPy</a></b> is one of the principal packages for scientific applications of Python. It is intended for processing large multidimensional arrays and matrices, and an extensive collection of high-level mathematical functions and implemented methods makes it possible to perform various operations with these objects. </li>\n",
    "</font>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Our first step is to import them:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import glob\n",
    "import json # for loads\n",
    "import shutil\n",
    "\n",
    "import gdal\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import HTML, display, Markdown, clear_output\n",
    "from ipywidgets import interact, Button, HBox, Layout\n",
    "\n",
    "from asf_notebook import earthdata_hyp3_login\n",
    "from asf_notebook import new_directory\n",
    "from asf_notebook import get_wget_cmd\n",
    "from asf_notebook import asf_unzip\n",
    "from asf_notebook import path_exists\n",
    "from asf_notebook import get_RTC_polarizations\n",
    "from asf_notebook import get_hyp3_subscriptions\n",
    "from asf_notebook import gui_date_picker\n",
    "from asf_notebook import get_subscription_products_info\n",
    "from asf_notebook import get_products_dates\n",
    "from asf_notebook import get_product_info\n",
    "from asf_notebook import select_parameter\n",
    "from asf_notebook import select_mult_parameters\n",
    "from asf_notebook import get_slider_vals\n",
    "from asf_notebook import input_path\n",
    "from asf_notebook import handle_old_data\n",
    "from asf_notebook import get_power_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\">\n",
    "\n",
    "<font size=\"5\"> <b> 1. Load Your Own Data Stack Into the Notebook </b> </font> \n",
    "\n",
    "<font size=\"3\"> This notebook assumes that you've created your own data stack over your personal area of interest using the <a href=\"https://www.asf.alaska.edu/\" target=\"_blank\">Alaska Satellite Facility's</a> value-added product system <a href=\"http://hyp3.asf.alaska.edu/\" target=\"_blank\">HyP3</a>. HyP3 is an environment that is used by ASF to prototype value added products and provide them to users to collect feedback. \n",
    "\n",
    "This lab expects <a href=\"https://media.asf.alaska.edu/uploads/RTC/rtc_atbd_v1.2_final.pdf\" target=\"_blank\">Radiometric Terrain Corrected</a> (RTC) image products as input, so be sure to select an RTC process when creating the subscription for your input data within HyP. Prefer a unique orbit geometry **(choose ascending or descending, not both)** to keep geometric differences between images low. \n",
    "\n",
    "We will retrieve HyP3 data via the HyP3 API. As both HyP3 and the Notebook environment sit in the <a href=\"https://aws.amazon.com/\" target=\"_blank\">Amazon Web Services (AWS)</a> cloud, data transfer is quick and cost effective.</font> \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\"> To download data from ASF, you need to provide your <a href=\"https://www.asf.alaska.edu/get-data/get-started/free-earthdata-account/\" target=\"_blank\">NASA Earth Data</a> username to the system. Setup an EarthData account if you do not yet have one. <font color='rgba(200,0,0,0.2)'><b>Note that EarthData's End User License Agreement (EULA) applies when accessing the Hyp3 API from this notebook. If you have not acknowleged the EULA in EarthData, you will need to navigate to <a href=\"https://earthdata.nasa.gov/\" target=\"_blank\">EarthData's home page</a> and complete that process.</b></font>\n",
    "<br><br>\n",
    "<b>Login to Earthdata:</b> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "api = earthdata_hyp3_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\"> Before we download anything, create a working directory for this analysis and change into it. \n",
    "<br><br>\n",
    "<b>Select or create a working directory for the analysis:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    data_dir = input_path()\n",
    "    if os.path.exists(data_dir):\n",
    "        contents = glob.glob(f'{data_dir}/*')\n",
    "        if len(contents) > 0:\n",
    "            choice = handle_old_data(data_dir, contents)\n",
    "            if choice == 1:\n",
    "                shutil.rmtree(data_dir)\n",
    "                os.mkdir(data_dir)\n",
    "                break\n",
    "            else:\n",
    "                clear_output()\n",
    "                continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        os.mkdir(data_dir)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Change into the analysis directory:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_directory = f\"{os.getcwd()}/{data_dir}\"\n",
    "os.chdir(analysis_directory)\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a folder in which to download your RTC products.</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtc_path = \"rtc_products\"\n",
    "new_directory(rtc_path)\n",
    "products_path = f\"{analysis_directory}/{rtc_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>List subscriptions and select one:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscriptions = get_hyp3_subscriptions(api)\n",
    "subscription = select_parameter('Subscriptions:', subscriptions)\n",
    "subscription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the selected subscription ID:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = subscription.value.split(':')[0]\n",
    "print(subscription_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Select a date range of products to download:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_info = get_subscription_products_info(subscription_id, api)\n",
    "dates = get_products_dates(products_info)\n",
    "date_picker = gui_date_picker(dates)\n",
    "date_picker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the selected date range:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_range = get_slider_vals(date_picker)\n",
    "date_range[0] = date_range[0].date()\n",
    "date_range[1] = date_range[1].date()\n",
    "print(f\"Date Range: {str(date_range[0])} to {str(date_range[1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Gather the available paths, flight directions, and download_urls for the subscription, inside the selected date range:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"<text style='color:red;'><text style='font-size:150%;'>This may take some time for large subscriptions...</text></text>\"))\n",
    "product_info = get_product_info(products_info, date_range)\n",
    "display(Markdown(f\"<text style=color:blue><text style='font-size:175%;'>Done.</text></text>\"))\n",
    "paths = set(product_info['paths'])\n",
    "paths.add('All Paths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Select a path or paths (use shift or ctrl to select multiple paths):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_choice = select_mult_parameters('Paths:', paths)\n",
    "path_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the selected flight path/s:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = path_choice.value\n",
    "if fp:\n",
    "    if 'All Paths' in fp:\n",
    "        flight_path = None\n",
    "    else:\n",
    "        flight_path = \"\"\n",
    "        for pth in fp:\n",
    "            if flight_path == \"\":\n",
    "                flight_path = f\"{pth}\"\n",
    "            else:\n",
    "                flight_path = f\"{flight_path}, {pth}\"\n",
    "    if flight_path:\n",
    "        print(f\"Flight Path: {flight_path}\")\n",
    "    else:\n",
    "        print(\"Flight Path: All Paths\")\n",
    "else:\n",
    "    print(\"WARNING: You must select a flight path in the previous cell, then rerun this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Select an orbit Direction:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_directions = set()\n",
    "for i, path in enumerate(product_info['paths']):\n",
    "    if not flight_path or path in flight_path:\n",
    "        valid_directions.add(product_info['directions'][i])\n",
    "\n",
    "direction_choice = select_parameter('Direction:', valid_directions)\n",
    "direction_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the selected orbit direction:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = direction_choice.value\n",
    "print(f\"Orbit Direction: {direction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a list of download_urls within the date range, filtered by orbit direction and flight path:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_urls = []\n",
    "for i, orbit_dir in enumerate(product_info['directions']):\n",
    "    if orbit_dir == direction:\n",
    "        if flight_path == None or product_info['paths'][i] == str(flight_path):  #change to allow mult flight paths\n",
    "            download_urls.append(product_info['urls'][i])\n",
    "download_urls.sort()\n",
    "print(f\"There are {len(download_urls)} products to download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Download the products, unzip them into the rtc_products directory, and delete the zip files:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path_exists(products_path):\n",
    "    product_count = 1\n",
    "    print(f\"\\nSubscription ID: {subscription_id}\")\n",
    "    for url in download_urls:\n",
    "        print(f\"\\nProduct Number {product_count} of {len(download_urls)}:\")\n",
    "        product_count += 1\n",
    "        product = url.split('/')[5]\n",
    "        filename = f\"{products_path}/{product}\"\n",
    "        # if not already present, we need to download and unzip products\n",
    "        if not os.path.exists(filename.split('.zip')[0]):\n",
    "            print(\n",
    "                f\"\\n{product} is not present.\\nDownloading from {url}\")\n",
    "            cmd = get_wget_cmd(url)\n",
    "            !$cmd\n",
    "            print(f\"\\n\")\n",
    "            asf_unzip(products_path, product)\n",
    "            print(f\"product: {product}\")\n",
    "            try:\n",
    "                os.remove(product)\n",
    "            except OSError:\n",
    "                pass\n",
    "            print(f\"\\nDone.\")\n",
    "        else:\n",
    "            print(f\"{filename} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Determine the subscription's process type.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_info = api.get_subscription(subscription_id)\n",
    "process_type = subscription_info['process_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Determine the available polarizations:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarizations = get_RTC_polarizations(process_type, rtc_path)\n",
    "polarization_power_set = get_power_set(polarizations, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Select a polarization:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarization_choice = select_parameter('Polarizations:', sorted(polarization_power_set))\n",
    "polarization_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a paths variable, holding the relative path to the tiffs in the selected polarization/s:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarization = polarization_choice.value\n",
    "if len(polarization) == 2:\n",
    "    paths = f\"{rtc_path}/*/*{polarization}.tif\"\n",
    "    dbl_polar = False\n",
    "else:\n",
    "    paths = f\"{rtc_path}/*/*{polarization[0]}*.tif\"\n",
    "    dbl_polar = True\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\"> You may notice duplicates in your acquisition dates. As HyP3 processes SAR data on a frame-by-frame basis, duplicates may occur if your area of interest is covered by two consecutive  image frames. In this case, two separate images are generated that need to be merged together before time series processing can commence.\n",
    "<br><br>\n",
    "<b>Write functions to collect and print the paths of the tiffs:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiff_paths(paths):\n",
    "    tiff_paths = !ls $paths | sort -t_ -k5,5\n",
    "    return tiff_paths\n",
    "\n",
    "def print_tiff_paths(tiff_paths):\n",
    "    print(\"Tiff paths:\")\n",
    "    for p in tiff_paths:\n",
    "        print(f\"{p}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Write a function to collect the product acquisition dates:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(paths):\n",
    "    dates = []\n",
    "    pths = glob.glob(paths)\n",
    "    for p in pths:\n",
    "        date = p.split(\"_\")[5][0:8]\n",
    "        dates.append(date)\n",
    "    dates.sort()\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Collect and print the paths of the tiffs:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_paths = get_tiff_paths(paths)\n",
    "#print_tiff_paths(tiff_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"4\"> <b>1.2 Fix multiple UTM Zone-related issues</b> <br>\n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\">Fix multiple UTM Zone-related issues should they exist in your data set. If multiple UTM zones are found, the following code cells will identify the predominant UTM zone and reproject the rest into that zone. This step must be completed prior to merging frames or performing any analysis.</font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Use gdal.Info to determine the UTM definition types and zones in each product:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utm_zones = []\n",
    "utm_types = []\n",
    "print('Checking UTM Zones in the data stack ...\\n')\n",
    "for k in range(0, len(tiff_paths)):\n",
    "    info = (gdal.Info(tiff_paths[k], options = ['-json']))\n",
    "    info = (json.loads(info))['coordinateSystem']['wkt']\n",
    "    zone = info[(len(info)-8):(len(info)-3)]\n",
    "    utm_zones.append(zone)\n",
    "    typ = info[(len(info)-15):(len(info)-11)]\n",
    "    utm_types.append(typ)\n",
    "print(f\"UTM Zones:\\n {utm_zones}\\n\")\n",
    "print(f\"UTM Types:\\n {utm_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Identify the most commonly used UTM Zone in the data:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utm_unique, counts = np.unique(utm_zones, return_counts=True)\n",
    "a = np.where(counts == np.max(counts))\n",
    "predominate_utm = utm_unique[a][0]\n",
    "print(f\"Predominate UTM Zone: {predominate_utm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Reproject tiffs with errant UTMs to the predominate UTM:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_indicies = [i for i, j in enumerate(utm_zones) if j != predominate_utm] #makes list of indicies in utm_zones that need to be reprojected\n",
    "print('--------------------------------------------')\n",
    "print('Reprojecting %4.1f files' %(len(reproject_indicies)))\n",
    "print('--------------------------------------------')\n",
    "for k in reproject_indicies:\n",
    "    temppath = tiff_paths[k].strip()\n",
    "    _, product_name, tiff_name = temppath.split('/')\n",
    "    cmd = f\"gdalwarp -overwrite rtc_products/{product_name}/{tiff_name} rtc_products/{product_name}/r{tiff_name} -s_srs {utm_types[k]}:{utm_zones[k]} -t_srs EPSG:{predominate_utm}\"\n",
    "    #print(f\"Calling the command: {cmd}\")\n",
    "    !{cmd}\n",
    "    rm_command = f\"rm {tiff_paths[k].strip()}\"\n",
    "    #print(f\"Calling the command: {rm_command}\")\n",
    "    !{rm_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Update tiff_paths with any new filenames created during reprojection:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_paths = get_tiff_paths(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"4\"> <b>1.3 Merge multiple frames from the same date.</b></font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Create a list of relative paths to the tiffs in each selected polarization:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dbl_polar:\n",
    "    rel_paths = [f\"{rtc_path}/*/*{polarization.split(' ')[0]}.tif\", \n",
    "                 f\"{rtc_path}/*/*{polarization.split(' ')[2]}.tif\"]\n",
    "else:\n",
    "    rel_paths = [paths]\n",
    "                 \n",
    "print(rel_paths)                 \n",
    "dates = get_dates(rel_paths[0])                 \n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a set containing each represented date:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = set(dates)\n",
    "print(unique_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Determine which dates have multiple frames. Create a dictionary with each date as a key linked to a value set as an empty string:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_date_batches = [{}]\n",
    "for date in unique_dates:\n",
    "    count = 0\n",
    "    for d in dates:\n",
    "        if date == d:\n",
    "            count +=1\n",
    "    if count > 1:\n",
    "        dup_date_batches[0].update({date : \"\"})\n",
    "if dbl_polar:\n",
    "    dup_date_batches.append(copy.deepcopy(dup_date_batches[0]))\n",
    "print(dup_date_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Update the key values in dup_paths with the string paths to all the tiffs for each date:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rel_pth in enumerate(rel_paths):\n",
    "    polar_paths = get_tiff_paths(rel_pth)\n",
    "    for pth in polar_paths:\n",
    "        date = pth.split('/')[2].split('_')[3][:8]\n",
    "        if date in dup_date_batches[i]:\n",
    "            dup_date_batches[i][date] = f\"{dup_date_batches[i][date]} {pth}\"\n",
    "\n",
    "for d in dup_date_batches:\n",
    "    for dd in d:\n",
    "        print(d)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Merge all the frames for each date.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dup_dates in enumerate(dup_date_batches):\n",
    "    for dup_date in dup_dates:\n",
    "        output = f\"{dup_dates[dup_date].split('/')[0]}/{dup_dates[dup_date].split('/')[1]}/new{dup_dates[dup_date].split('/')[2].split(' ')[0]}\"\n",
    "        gdal_command = f\"gdal_merge.py -o {output} {dup_dates[dup_date]}\"\n",
    "        print(f\"\\n\\nCalling the command: {gdal_command}\\n\")\n",
    "        !{gdal_command}\n",
    "        for pth in dup_dates[dup_date].split(' '):\n",
    "            if pth and path_exists(pth):\n",
    "                os.remove(pth)\n",
    "                print(f\"Deleting: {pth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>Verify that all duplicate dates were resolved:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rel_pth in rel_paths:\n",
    "    dates = get_dates(rel_pth)\n",
    "    if len(dates) != len(set(dates)):\n",
    "        print(f\"Duplicate dates still present!\")\n",
    "    else:\n",
    "        print(f\"No duplicate dates are associated with {rel_pth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Update the paths of the tiffs:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_paths = get_tiff_paths(paths)\n",
    "#print_tiff_paths(tiff_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a tiffs folder, move the tiffs into it, and delete the rtc_products folder:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_directory(\"tiffs\")\n",
    "for tiff in tiff_paths:\n",
    "    os.rename(tiff, f\"{analysis_directory}/tiffs/{tiff.split('/')[-1]}\")\n",
    "shutil.rmtree(rtc_path)              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Print the path where you saved your tiffs.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{analysis_directory}/tiffs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>GEOS 657 Microwave Remote Sensing - Version 1.0 - April 2019 </i>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
